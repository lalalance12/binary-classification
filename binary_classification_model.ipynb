{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U8ih6-sQhG7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    # Our activation function: f(x) = 1 / (1 + e^(-x))\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def deriv_sigmoid(x):\n",
        "    # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n",
        "    fx = sigmoid(x)\n",
        "    return fx * (1 - fx)\n",
        "\n",
        "def mse_loss(y_true, y_pred):\n",
        "    # y_true and y_pred are numpy arrays of the same length.\n",
        "    return ((y_true - y_pred) ** 2).mean()"
      ],
      "metadata": {
        "id": "r4ZsHaXTQmy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights and biases generated randomly\n",
        "weights = np.array([0.187123, -0.1918723, 0.012653, -1.12263, 1.17236, 0.22234])\n",
        "bias = np.array([1.71326, 0.7128397, -0.327839])\n"
      ],
      "metadata": {
        "id": "mp_VKWP_UM7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OurNeuralNetwork:\n",
        "    def __init__(self):\n",
        "        # Weights\n",
        "        self.weights = weights\n",
        "        self.w1 = self.weights[0]\n",
        "        self.w2 = self.weights[1]\n",
        "        self.w3 = self.weights[2]\n",
        "        self.w4 = self.weights[3]\n",
        "        self.w5 = self.weights[4]\n",
        "        self.w6 = self.weights[5]\n",
        "\n",
        "        # Biases\n",
        "        self.bias = bias\n",
        "        self.b1 = self.bias[0]\n",
        "        self.b2 = self.bias[1]\n",
        "        self.b3 = self.bias[2]\n",
        "\n",
        "    def feedforward(self, x):\n",
        "\n",
        "        h1 = sigmoid(self.w1 * x[0] + self.w2 * x[1] + self.b1)\n",
        "        h2 = sigmoid(self.w3 * x[0] + self.w4 * x[1] + self.b2)\n",
        "        o1 = sigmoid(self.w5 * h1 + self.w6 * h2 + self.b3)\n",
        "        return o1\n",
        "\n",
        "    def train(self, data, all_y_trues):\n",
        "        learn_rate = 0.1\n",
        "        epochs = 5000 # number of times to loop through the entire dataset\n",
        "\n",
        "        mse = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for x, y_true in zip(data, all_y_trues):\n",
        "                # --- Do a feedforward (we'll need these values later)\n",
        "                sum_h1 = self.w1 * x[0] + self.w2 * x[1] + self.b1\n",
        "                h1 = sigmoid(sum_h1)\n",
        "\n",
        "                sum_h2 = self.w3 * x[0] + self.w4 * x[1] + self.b2\n",
        "                h2 = sigmoid(sum_h2)\n",
        "\n",
        "                sum_o1 = self.w5 * h1 + self.w6 * h2 + self.b3\n",
        "                o1 = sigmoid(sum_o1)\n",
        "                y_pred = o1\n",
        "\n",
        "                # --- Calculate partial derivatives.\n",
        "                # --- Naming: d_L_d_w1 represents \"partial L / partial w1\"\n",
        "                d_L_d_ypred = -2 * (y_true - y_pred)\n",
        "\n",
        "                # Neuron o1\n",
        "                d_ypred_d_w5 = h1 * deriv_sigmoid(sum_o1)\n",
        "                d_ypred_d_w6 = h2 * deriv_sigmoid(sum_o1)\n",
        "                d_ypred_d_b3 = deriv_sigmoid(sum_o1)\n",
        "\n",
        "                d_ypred_d_h1 = self.w5 * deriv_sigmoid(sum_o1)\n",
        "                d_ypred_d_h2 = self.w6 * deriv_sigmoid(sum_o1)\n",
        "\n",
        "                # Neuron h1\n",
        "                d_h1_d_w1 = x[0] * deriv_sigmoid(sum_h1)\n",
        "                d_h1_d_w2 = x[1] * deriv_sigmoid(sum_h1)\n",
        "                d_h1_d_b1 = deriv_sigmoid(sum_h1)\n",
        "\n",
        "                # Neuron h2\n",
        "                d_h2_d_w3 = x[0] * deriv_sigmoid(sum_h2)\n",
        "                d_h2_d_w4 = x[1] * deriv_sigmoid(sum_h2)\n",
        "                d_h2_d_b2 = deriv_sigmoid(sum_h2)\n",
        "\n",
        "                # --- Update weights and biases\n",
        "                # Neuron h1\n",
        "                self.w1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
        "                self.w2 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2\n",
        "                self.b1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1\n",
        "\n",
        "                # Neuron h2\n",
        "                self.w3 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w3\n",
        "                self.w4 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4\n",
        "                self.b2 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
        "\n",
        "                # Neuron o1\n",
        "                self.w5 -= learn_rate * d_L_d_ypred * d_ypred_d_w5\n",
        "                self.w6 -= learn_rate * d_L_d_ypred * d_ypred_d_w6\n",
        "                self.b3 -= learn_rate * d_L_d_ypred * d_ypred_d_b3\n",
        "\n",
        "            # --- Calculate total loss at the end of each epoch\n",
        "            if epoch % 10 == 0:\n",
        "                y_preds = np.apply_along_axis(self.feedforward, 1, data)\n",
        "                loss = mse_loss(all_y_trues, y_preds)\n",
        "                mse.append(loss)\n",
        "                print(\"Epoch %d loss: %.3f\" % (epoch, loss))\n",
        "\n",
        "        plt.plot(mse, label='Loss', color='blue')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aG_5o2IZQm06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the large dataset\n",
        "dataset = pd.read_csv('trainingdataset.csv')\n",
        "\n",
        "# Convert 'Classification' column to numerical values (Good=1, Bad=0)\n",
        "dataset['Classification'] = dataset['Classification'].map({'Good': 1, 'Bad': 0})\n",
        "\n",
        "data = dataset[['Area', 'Bathrooms']].to_numpy()\n",
        "all_y_trues = dataset['Classification'].to_numpy()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "dataset_scaled = scaler.fit_transform(data)\n"
      ],
      "metadata": {
        "id": "sqsKgkMtQm25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Initialize and train the neural network\n",
        "network = OurNeuralNetwork()\n",
        "network.train(dataset_scaled, all_y_trues)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZhzS1He-Qm4t",
        "outputId": "4fd85159-5b36-48c0-f353-c10a3c81031b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 loss: 0.211\n",
            "Epoch 10 loss: 0.211\n",
            "Epoch 20 loss: 0.211\n",
            "Epoch 30 loss: 0.211\n",
            "Epoch 40 loss: 0.211\n",
            "Epoch 50 loss: 0.211\n",
            "Epoch 60 loss: 0.211\n",
            "Epoch 70 loss: 0.210\n",
            "Epoch 80 loss: 0.210\n",
            "Epoch 90 loss: 0.210\n",
            "Epoch 100 loss: 0.210\n",
            "Epoch 110 loss: 0.210\n",
            "Epoch 120 loss: 0.210\n",
            "Epoch 130 loss: 0.210\n",
            "Epoch 140 loss: 0.210\n",
            "Epoch 150 loss: 0.210\n",
            "Epoch 160 loss: 0.210\n",
            "Epoch 170 loss: 0.210\n",
            "Epoch 180 loss: 0.210\n",
            "Epoch 190 loss: 0.210\n",
            "Epoch 200 loss: 0.210\n",
            "Epoch 210 loss: 0.209\n",
            "Epoch 220 loss: 0.209\n",
            "Epoch 230 loss: 0.209\n",
            "Epoch 240 loss: 0.209\n",
            "Epoch 250 loss: 0.209\n",
            "Epoch 260 loss: 0.209\n",
            "Epoch 270 loss: 0.209\n",
            "Epoch 280 loss: 0.209\n",
            "Epoch 290 loss: 0.209\n",
            "Epoch 300 loss: 0.208\n",
            "Epoch 310 loss: 0.208\n",
            "Epoch 320 loss: 0.208\n",
            "Epoch 330 loss: 0.208\n",
            "Epoch 340 loss: 0.208\n",
            "Epoch 350 loss: 0.207\n",
            "Epoch 360 loss: 0.207\n",
            "Epoch 370 loss: 0.207\n",
            "Epoch 380 loss: 0.207\n",
            "Epoch 390 loss: 0.206\n",
            "Epoch 400 loss: 0.206\n",
            "Epoch 410 loss: 0.206\n",
            "Epoch 420 loss: 0.205\n",
            "Epoch 430 loss: 0.205\n",
            "Epoch 440 loss: 0.204\n",
            "Epoch 450 loss: 0.204\n",
            "Epoch 460 loss: 0.204\n",
            "Epoch 470 loss: 0.203\n",
            "Epoch 480 loss: 0.203\n",
            "Epoch 490 loss: 0.202\n",
            "Epoch 500 loss: 0.202\n",
            "Epoch 510 loss: 0.202\n",
            "Epoch 520 loss: 0.201\n",
            "Epoch 530 loss: 0.201\n",
            "Epoch 540 loss: 0.200\n",
            "Epoch 550 loss: 0.200\n",
            "Epoch 560 loss: 0.200\n",
            "Epoch 570 loss: 0.199\n",
            "Epoch 580 loss: 0.199\n",
            "Epoch 590 loss: 0.198\n",
            "Epoch 600 loss: 0.198\n",
            "Epoch 610 loss: 0.198\n",
            "Epoch 620 loss: 0.197\n",
            "Epoch 630 loss: 0.197\n",
            "Epoch 640 loss: 0.196\n",
            "Epoch 650 loss: 0.196\n",
            "Epoch 660 loss: 0.196\n",
            "Epoch 670 loss: 0.195\n",
            "Epoch 680 loss: 0.195\n",
            "Epoch 690 loss: 0.194\n",
            "Epoch 700 loss: 0.194\n",
            "Epoch 710 loss: 0.194\n",
            "Epoch 720 loss: 0.193\n",
            "Epoch 730 loss: 0.193\n",
            "Epoch 740 loss: 0.192\n",
            "Epoch 750 loss: 0.192\n",
            "Epoch 760 loss: 0.192\n",
            "Epoch 770 loss: 0.191\n",
            "Epoch 780 loss: 0.191\n",
            "Epoch 790 loss: 0.190\n",
            "Epoch 800 loss: 0.190\n",
            "Epoch 810 loss: 0.189\n",
            "Epoch 820 loss: 0.189\n",
            "Epoch 830 loss: 0.188\n",
            "Epoch 840 loss: 0.188\n",
            "Epoch 850 loss: 0.187\n",
            "Epoch 860 loss: 0.187\n",
            "Epoch 870 loss: 0.186\n",
            "Epoch 880 loss: 0.186\n",
            "Epoch 890 loss: 0.185\n",
            "Epoch 900 loss: 0.184\n",
            "Epoch 910 loss: 0.184\n",
            "Epoch 920 loss: 0.183\n",
            "Epoch 930 loss: 0.182\n",
            "Epoch 940 loss: 0.181\n",
            "Epoch 950 loss: 0.180\n",
            "Epoch 960 loss: 0.179\n",
            "Epoch 970 loss: 0.178\n",
            "Epoch 980 loss: 0.177\n",
            "Epoch 990 loss: 0.176\n",
            "Epoch 1000 loss: 0.174\n",
            "Epoch 1010 loss: 0.173\n",
            "Epoch 1020 loss: 0.171\n",
            "Epoch 1030 loss: 0.170\n",
            "Epoch 1040 loss: 0.168\n",
            "Epoch 1050 loss: 0.166\n",
            "Epoch 1060 loss: 0.164\n",
            "Epoch 1070 loss: 0.162\n",
            "Epoch 1080 loss: 0.160\n",
            "Epoch 1090 loss: 0.158\n",
            "Epoch 1100 loss: 0.156\n",
            "Epoch 1110 loss: 0.153\n",
            "Epoch 1120 loss: 0.151\n",
            "Epoch 1130 loss: 0.149\n",
            "Epoch 1140 loss: 0.147\n",
            "Epoch 1150 loss: 0.144\n",
            "Epoch 1160 loss: 0.142\n",
            "Epoch 1170 loss: 0.140\n",
            "Epoch 1180 loss: 0.138\n",
            "Epoch 1190 loss: 0.136\n",
            "Epoch 1200 loss: 0.134\n",
            "Epoch 1210 loss: 0.132\n",
            "Epoch 1220 loss: 0.130\n",
            "Epoch 1230 loss: 0.128\n",
            "Epoch 1240 loss: 0.126\n",
            "Epoch 1250 loss: 0.125\n",
            "Epoch 1260 loss: 0.123\n",
            "Epoch 1270 loss: 0.121\n",
            "Epoch 1280 loss: 0.120\n",
            "Epoch 1290 loss: 0.119\n",
            "Epoch 1300 loss: 0.117\n",
            "Epoch 1310 loss: 0.116\n",
            "Epoch 1320 loss: 0.115\n",
            "Epoch 1330 loss: 0.114\n",
            "Epoch 1340 loss: 0.113\n",
            "Epoch 1350 loss: 0.112\n",
            "Epoch 1360 loss: 0.111\n",
            "Epoch 1370 loss: 0.110\n",
            "Epoch 1380 loss: 0.109\n",
            "Epoch 1390 loss: 0.109\n",
            "Epoch 1400 loss: 0.108\n",
            "Epoch 1410 loss: 0.107\n",
            "Epoch 1420 loss: 0.106\n",
            "Epoch 1430 loss: 0.106\n",
            "Epoch 1440 loss: 0.105\n",
            "Epoch 1450 loss: 0.105\n",
            "Epoch 1460 loss: 0.104\n",
            "Epoch 1470 loss: 0.103\n",
            "Epoch 1480 loss: 0.103\n",
            "Epoch 1490 loss: 0.102\n",
            "Epoch 1500 loss: 0.102\n",
            "Epoch 1510 loss: 0.102\n",
            "Epoch 1520 loss: 0.101\n",
            "Epoch 1530 loss: 0.101\n",
            "Epoch 1540 loss: 0.100\n",
            "Epoch 1550 loss: 0.100\n",
            "Epoch 1560 loss: 0.100\n",
            "Epoch 1570 loss: 0.099\n",
            "Epoch 1580 loss: 0.099\n",
            "Epoch 1590 loss: 0.099\n",
            "Epoch 1600 loss: 0.098\n",
            "Epoch 1610 loss: 0.098\n",
            "Epoch 1620 loss: 0.098\n",
            "Epoch 1630 loss: 0.097\n",
            "Epoch 1640 loss: 0.097\n",
            "Epoch 1650 loss: 0.097\n",
            "Epoch 1660 loss: 0.097\n",
            "Epoch 1670 loss: 0.096\n",
            "Epoch 1680 loss: 0.096\n",
            "Epoch 1690 loss: 0.096\n",
            "Epoch 1700 loss: 0.096\n",
            "Epoch 1710 loss: 0.096\n",
            "Epoch 1720 loss: 0.095\n",
            "Epoch 1730 loss: 0.095\n",
            "Epoch 1740 loss: 0.095\n",
            "Epoch 1750 loss: 0.095\n",
            "Epoch 1760 loss: 0.095\n",
            "Epoch 1770 loss: 0.094\n",
            "Epoch 1780 loss: 0.094\n",
            "Epoch 1790 loss: 0.094\n",
            "Epoch 1800 loss: 0.094\n",
            "Epoch 1810 loss: 0.094\n",
            "Epoch 1820 loss: 0.094\n",
            "Epoch 1830 loss: 0.093\n",
            "Epoch 1840 loss: 0.093\n",
            "Epoch 1850 loss: 0.093\n",
            "Epoch 1860 loss: 0.093\n",
            "Epoch 1870 loss: 0.093\n",
            "Epoch 1880 loss: 0.093\n",
            "Epoch 1890 loss: 0.093\n",
            "Epoch 1900 loss: 0.093\n",
            "Epoch 1910 loss: 0.092\n",
            "Epoch 1920 loss: 0.092\n",
            "Epoch 1930 loss: 0.092\n",
            "Epoch 1940 loss: 0.092\n",
            "Epoch 1950 loss: 0.092\n",
            "Epoch 1960 loss: 0.092\n",
            "Epoch 1970 loss: 0.092\n",
            "Epoch 1980 loss: 0.092\n",
            "Epoch 1990 loss: 0.092\n",
            "Epoch 2000 loss: 0.092\n",
            "Epoch 2010 loss: 0.091\n",
            "Epoch 2020 loss: 0.091\n",
            "Epoch 2030 loss: 0.091\n",
            "Epoch 2040 loss: 0.091\n",
            "Epoch 2050 loss: 0.091\n",
            "Epoch 2060 loss: 0.091\n",
            "Epoch 2070 loss: 0.091\n",
            "Epoch 2080 loss: 0.091\n",
            "Epoch 2090 loss: 0.091\n",
            "Epoch 2100 loss: 0.091\n",
            "Epoch 2110 loss: 0.091\n",
            "Epoch 2120 loss: 0.091\n",
            "Epoch 2130 loss: 0.091\n",
            "Epoch 2140 loss: 0.091\n",
            "Epoch 2150 loss: 0.090\n",
            "Epoch 2160 loss: 0.090\n",
            "Epoch 2170 loss: 0.090\n",
            "Epoch 2180 loss: 0.090\n",
            "Epoch 2190 loss: 0.090\n",
            "Epoch 2200 loss: 0.090\n",
            "Epoch 2210 loss: 0.090\n",
            "Epoch 2220 loss: 0.090\n",
            "Epoch 2230 loss: 0.090\n",
            "Epoch 2240 loss: 0.090\n",
            "Epoch 2250 loss: 0.090\n",
            "Epoch 2260 loss: 0.090\n",
            "Epoch 2270 loss: 0.090\n",
            "Epoch 2280 loss: 0.090\n",
            "Epoch 2290 loss: 0.090\n",
            "Epoch 2300 loss: 0.090\n",
            "Epoch 2310 loss: 0.090\n",
            "Epoch 2320 loss: 0.090\n",
            "Epoch 2330 loss: 0.090\n",
            "Epoch 2340 loss: 0.089\n",
            "Epoch 2350 loss: 0.089\n",
            "Epoch 2360 loss: 0.089\n",
            "Epoch 2370 loss: 0.089\n",
            "Epoch 2380 loss: 0.089\n",
            "Epoch 2390 loss: 0.089\n",
            "Epoch 2400 loss: 0.089\n",
            "Epoch 2410 loss: 0.089\n",
            "Epoch 2420 loss: 0.089\n",
            "Epoch 2430 loss: 0.089\n",
            "Epoch 2440 loss: 0.089\n",
            "Epoch 2450 loss: 0.089\n",
            "Epoch 2460 loss: 0.089\n",
            "Epoch 2470 loss: 0.089\n",
            "Epoch 2480 loss: 0.089\n",
            "Epoch 2490 loss: 0.089\n",
            "Epoch 2500 loss: 0.089\n",
            "Epoch 2510 loss: 0.089\n",
            "Epoch 2520 loss: 0.089\n",
            "Epoch 2530 loss: 0.089\n",
            "Epoch 2540 loss: 0.089\n",
            "Epoch 2550 loss: 0.089\n",
            "Epoch 2560 loss: 0.089\n",
            "Epoch 2570 loss: 0.089\n",
            "Epoch 2580 loss: 0.089\n",
            "Epoch 2590 loss: 0.089\n",
            "Epoch 2600 loss: 0.089\n",
            "Epoch 2610 loss: 0.089\n",
            "Epoch 2620 loss: 0.089\n",
            "Epoch 2630 loss: 0.088\n",
            "Epoch 2640 loss: 0.088\n",
            "Epoch 2650 loss: 0.088\n",
            "Epoch 2660 loss: 0.088\n",
            "Epoch 2670 loss: 0.088\n",
            "Epoch 2680 loss: 0.088\n",
            "Epoch 2690 loss: 0.088\n",
            "Epoch 2700 loss: 0.088\n",
            "Epoch 2710 loss: 0.088\n",
            "Epoch 2720 loss: 0.088\n",
            "Epoch 2730 loss: 0.088\n",
            "Epoch 2740 loss: 0.088\n",
            "Epoch 2750 loss: 0.088\n",
            "Epoch 2760 loss: 0.088\n",
            "Epoch 2770 loss: 0.088\n",
            "Epoch 2780 loss: 0.088\n",
            "Epoch 2790 loss: 0.088\n",
            "Epoch 2800 loss: 0.088\n",
            "Epoch 2810 loss: 0.088\n",
            "Epoch 2820 loss: 0.088\n",
            "Epoch 2830 loss: 0.088\n",
            "Epoch 2840 loss: 0.088\n",
            "Epoch 2850 loss: 0.088\n",
            "Epoch 2860 loss: 0.088\n",
            "Epoch 2870 loss: 0.088\n",
            "Epoch 2880 loss: 0.088\n",
            "Epoch 2890 loss: 0.088\n",
            "Epoch 2900 loss: 0.088\n",
            "Epoch 2910 loss: 0.088\n",
            "Epoch 2920 loss: 0.088\n",
            "Epoch 2930 loss: 0.088\n",
            "Epoch 2940 loss: 0.088\n",
            "Epoch 2950 loss: 0.088\n",
            "Epoch 2960 loss: 0.088\n",
            "Epoch 2970 loss: 0.088\n",
            "Epoch 2980 loss: 0.088\n",
            "Epoch 2990 loss: 0.088\n",
            "Epoch 3000 loss: 0.088\n",
            "Epoch 3010 loss: 0.088\n",
            "Epoch 3020 loss: 0.088\n",
            "Epoch 3030 loss: 0.088\n",
            "Epoch 3040 loss: 0.088\n",
            "Epoch 3050 loss: 0.088\n",
            "Epoch 3060 loss: 0.088\n",
            "Epoch 3070 loss: 0.088\n",
            "Epoch 3080 loss: 0.088\n",
            "Epoch 3090 loss: 0.088\n",
            "Epoch 3100 loss: 0.088\n",
            "Epoch 3110 loss: 0.088\n",
            "Epoch 3120 loss: 0.088\n",
            "Epoch 3130 loss: 0.088\n",
            "Epoch 3140 loss: 0.087\n",
            "Epoch 3150 loss: 0.087\n",
            "Epoch 3160 loss: 0.087\n",
            "Epoch 3170 loss: 0.087\n",
            "Epoch 3180 loss: 0.087\n",
            "Epoch 3190 loss: 0.087\n",
            "Epoch 3200 loss: 0.087\n",
            "Epoch 3210 loss: 0.087\n",
            "Epoch 3220 loss: 0.087\n",
            "Epoch 3230 loss: 0.087\n",
            "Epoch 3240 loss: 0.087\n",
            "Epoch 3250 loss: 0.087\n",
            "Epoch 3260 loss: 0.087\n",
            "Epoch 3270 loss: 0.087\n",
            "Epoch 3280 loss: 0.087\n",
            "Epoch 3290 loss: 0.087\n",
            "Epoch 3300 loss: 0.087\n",
            "Epoch 3310 loss: 0.087\n",
            "Epoch 3320 loss: 0.087\n",
            "Epoch 3330 loss: 0.087\n",
            "Epoch 3340 loss: 0.087\n",
            "Epoch 3350 loss: 0.087\n",
            "Epoch 3360 loss: 0.087\n",
            "Epoch 3370 loss: 0.087\n",
            "Epoch 3380 loss: 0.087\n",
            "Epoch 3390 loss: 0.087\n",
            "Epoch 3400 loss: 0.087\n",
            "Epoch 3410 loss: 0.087\n",
            "Epoch 3420 loss: 0.087\n",
            "Epoch 3430 loss: 0.087\n",
            "Epoch 3440 loss: 0.087\n",
            "Epoch 3450 loss: 0.087\n",
            "Epoch 3460 loss: 0.087\n",
            "Epoch 3470 loss: 0.087\n",
            "Epoch 3480 loss: 0.087\n",
            "Epoch 3490 loss: 0.087\n",
            "Epoch 3500 loss: 0.087\n",
            "Epoch 3510 loss: 0.087\n",
            "Epoch 3520 loss: 0.087\n",
            "Epoch 3530 loss: 0.087\n",
            "Epoch 3540 loss: 0.087\n",
            "Epoch 3550 loss: 0.087\n",
            "Epoch 3560 loss: 0.087\n",
            "Epoch 3570 loss: 0.087\n",
            "Epoch 3580 loss: 0.087\n",
            "Epoch 3590 loss: 0.087\n",
            "Epoch 3600 loss: 0.087\n",
            "Epoch 3610 loss: 0.087\n",
            "Epoch 3620 loss: 0.087\n",
            "Epoch 3630 loss: 0.087\n",
            "Epoch 3640 loss: 0.087\n",
            "Epoch 3650 loss: 0.087\n",
            "Epoch 3660 loss: 0.087\n",
            "Epoch 3670 loss: 0.087\n",
            "Epoch 3680 loss: 0.087\n",
            "Epoch 3690 loss: 0.087\n",
            "Epoch 3700 loss: 0.087\n",
            "Epoch 3710 loss: 0.087\n",
            "Epoch 3720 loss: 0.087\n",
            "Epoch 3730 loss: 0.087\n",
            "Epoch 3740 loss: 0.087\n",
            "Epoch 3750 loss: 0.087\n",
            "Epoch 3760 loss: 0.087\n",
            "Epoch 3770 loss: 0.087\n",
            "Epoch 3780 loss: 0.087\n",
            "Epoch 3790 loss: 0.087\n",
            "Epoch 3800 loss: 0.087\n",
            "Epoch 3810 loss: 0.087\n",
            "Epoch 3820 loss: 0.087\n",
            "Epoch 3830 loss: 0.087\n",
            "Epoch 3840 loss: 0.087\n",
            "Epoch 3850 loss: 0.087\n",
            "Epoch 3860 loss: 0.087\n",
            "Epoch 3870 loss: 0.087\n",
            "Epoch 3880 loss: 0.087\n",
            "Epoch 3890 loss: 0.087\n",
            "Epoch 3900 loss: 0.087\n",
            "Epoch 3910 loss: 0.087\n",
            "Epoch 3920 loss: 0.087\n",
            "Epoch 3930 loss: 0.087\n",
            "Epoch 3940 loss: 0.087\n",
            "Epoch 3950 loss: 0.087\n",
            "Epoch 3960 loss: 0.087\n",
            "Epoch 3970 loss: 0.087\n",
            "Epoch 3980 loss: 0.087\n",
            "Epoch 3990 loss: 0.087\n",
            "Epoch 4000 loss: 0.087\n",
            "Epoch 4010 loss: 0.087\n",
            "Epoch 4020 loss: 0.087\n",
            "Epoch 4030 loss: 0.087\n",
            "Epoch 4040 loss: 0.087\n",
            "Epoch 4050 loss: 0.087\n",
            "Epoch 4060 loss: 0.087\n",
            "Epoch 4070 loss: 0.087\n",
            "Epoch 4080 loss: 0.087\n",
            "Epoch 4090 loss: 0.087\n",
            "Epoch 4100 loss: 0.086\n",
            "Epoch 4110 loss: 0.086\n",
            "Epoch 4120 loss: 0.086\n",
            "Epoch 4130 loss: 0.086\n",
            "Epoch 4140 loss: 0.086\n",
            "Epoch 4150 loss: 0.086\n",
            "Epoch 4160 loss: 0.086\n",
            "Epoch 4170 loss: 0.086\n",
            "Epoch 4180 loss: 0.086\n",
            "Epoch 4190 loss: 0.086\n",
            "Epoch 4200 loss: 0.086\n",
            "Epoch 4210 loss: 0.086\n",
            "Epoch 4220 loss: 0.086\n",
            "Epoch 4230 loss: 0.086\n",
            "Epoch 4240 loss: 0.086\n",
            "Epoch 4250 loss: 0.086\n",
            "Epoch 4260 loss: 0.086\n",
            "Epoch 4270 loss: 0.086\n",
            "Epoch 4280 loss: 0.086\n",
            "Epoch 4290 loss: 0.086\n",
            "Epoch 4300 loss: 0.086\n",
            "Epoch 4310 loss: 0.086\n",
            "Epoch 4320 loss: 0.086\n",
            "Epoch 4330 loss: 0.086\n",
            "Epoch 4340 loss: 0.086\n",
            "Epoch 4350 loss: 0.086\n",
            "Epoch 4360 loss: 0.086\n",
            "Epoch 4370 loss: 0.086\n",
            "Epoch 4380 loss: 0.086\n",
            "Epoch 4390 loss: 0.086\n",
            "Epoch 4400 loss: 0.086\n",
            "Epoch 4410 loss: 0.086\n",
            "Epoch 4420 loss: 0.086\n",
            "Epoch 4430 loss: 0.086\n",
            "Epoch 4440 loss: 0.086\n",
            "Epoch 4450 loss: 0.086\n",
            "Epoch 4460 loss: 0.086\n",
            "Epoch 4470 loss: 0.086\n",
            "Epoch 4480 loss: 0.086\n",
            "Epoch 4490 loss: 0.086\n",
            "Epoch 4500 loss: 0.086\n",
            "Epoch 4510 loss: 0.086\n",
            "Epoch 4520 loss: 0.086\n",
            "Epoch 4530 loss: 0.086\n",
            "Epoch 4540 loss: 0.086\n",
            "Epoch 4550 loss: 0.086\n",
            "Epoch 4560 loss: 0.086\n",
            "Epoch 4570 loss: 0.086\n",
            "Epoch 4580 loss: 0.086\n",
            "Epoch 4590 loss: 0.086\n",
            "Epoch 4600 loss: 0.086\n",
            "Epoch 4610 loss: 0.086\n",
            "Epoch 4620 loss: 0.086\n",
            "Epoch 4630 loss: 0.086\n",
            "Epoch 4640 loss: 0.086\n",
            "Epoch 4650 loss: 0.086\n",
            "Epoch 4660 loss: 0.086\n",
            "Epoch 4670 loss: 0.086\n",
            "Epoch 4680 loss: 0.086\n",
            "Epoch 4690 loss: 0.086\n",
            "Epoch 4700 loss: 0.086\n",
            "Epoch 4710 loss: 0.086\n",
            "Epoch 4720 loss: 0.086\n",
            "Epoch 4730 loss: 0.086\n",
            "Epoch 4740 loss: 0.086\n",
            "Epoch 4750 loss: 0.086\n",
            "Epoch 4760 loss: 0.086\n",
            "Epoch 4770 loss: 0.086\n",
            "Epoch 4780 loss: 0.086\n",
            "Epoch 4790 loss: 0.086\n",
            "Epoch 4800 loss: 0.086\n",
            "Epoch 4810 loss: 0.086\n",
            "Epoch 4820 loss: 0.086\n",
            "Epoch 4830 loss: 0.086\n",
            "Epoch 4840 loss: 0.086\n",
            "Epoch 4850 loss: 0.086\n",
            "Epoch 4860 loss: 0.086\n",
            "Epoch 4870 loss: 0.086\n",
            "Epoch 4880 loss: 0.086\n",
            "Epoch 4890 loss: 0.086\n",
            "Epoch 4900 loss: 0.086\n",
            "Epoch 4910 loss: 0.086\n",
            "Epoch 4920 loss: 0.086\n",
            "Epoch 4930 loss: 0.086\n",
            "Epoch 4940 loss: 0.086\n",
            "Epoch 4950 loss: 0.086\n",
            "Epoch 4960 loss: 0.086\n",
            "Epoch 4970 loss: 0.086\n",
            "Epoch 4980 loss: 0.086\n",
            "Epoch 4990 loss: 0.086\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Scale and make predictions on new data (for example, [4000, 4])\n",
        "new_house = np.array([[2200, 3]])\n",
        "new_house_scaled = scaler.transform(new_house)\n",
        "print(\"New house prediction: %.3f\" % network.feedforward(new_house_scaled[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR4NLJzRQm6n",
        "outputId": "59f514b7-c132-4ba2-cf0d-082bd79d1dfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New house prediction: 0.911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the final weights and biases\n",
        "final_weights = network.weights\n",
        "final_bias = network.bias\n",
        "print(\"Final Weights:\", final_weights)\n",
        "print(\"Final Biases:\", final_bias)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JAth6sNUhLk",
        "outputId": "171cd1a4-a0b5-4993-bae2-f85bb1d84802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [ 0.187123  -0.1918723  0.012653  -1.12263    1.17236    0.22234  ]\n",
            "Final Biases: [ 1.71326    0.7128397 -0.327839 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Property dataset not found in the training dataset\n",
        "houses = np.array([\n",
        "    [2200, 3],\n",
        "    [4000, 4],\n",
        "    [3000, 2],\n",
        "    [1500, 1],\n",
        "    [5000, 5],\n",
        "    [2500, 3],\n",
        "    [3500, 4],\n",
        "    [1234, 3],\n",
        "    [2345, 2],\n",
        "    [3456, 4]\n",
        "])\n",
        "houses_scaled = scaler.transform(houses)\n",
        "threshold = 0.5  # Define the threshold\n",
        "\n",
        "print(\"Predictions for new houses:\")\n",
        "print(\"---------------------------\")\n",
        "for house, original_house in zip(houses_scaled, houses):\n",
        "    prediction = network.feedforward(house)\n",
        "    result = \"Good\" if prediction > threshold else \"Bad\"\n",
        "    print(f\"House with {original_house[0]} area and {original_house[1]} bathrooms:\")\n",
        "    print(f\"  Prediction: {prediction:.3f} - {result} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLS13LL2Qm8n",
        "outputId": "843c42ac-7020-4ffa-9b38-de8ebdadc6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for new houses:\n",
            "---------------------------\n",
            "House with 2200 area and 3 bathrooms:\n",
            "  Prediction: 0.911 - Good \n",
            "\n",
            "House with 4000 area and 4 bathrooms:\n",
            "  Prediction: 0.017 - Bad \n",
            "\n",
            "House with 3000 area and 2 bathrooms:\n",
            "  Prediction: 0.130 - Bad \n",
            "\n",
            "House with 1500 area and 1 bathrooms:\n",
            "  Prediction: 0.018 - Bad \n",
            "\n",
            "House with 5000 area and 5 bathrooms:\n",
            "  Prediction: 0.016 - Bad \n",
            "\n",
            "House with 2500 area and 3 bathrooms:\n",
            "  Prediction: 0.877 - Good \n",
            "\n",
            "House with 3500 area and 4 bathrooms:\n",
            "  Prediction: 0.021 - Bad \n",
            "\n",
            "House with 1234 area and 3 bathrooms:\n",
            "  Prediction: 0.777 - Good \n",
            "\n",
            "House with 2345 area and 2 bathrooms:\n",
            "  Prediction: 0.116 - Bad \n",
            "\n",
            "House with 3456 area and 4 bathrooms:\n",
            "  Prediction: 0.022 - Bad \n",
            "\n"
          ]
        }
      ]
    }
  ]
}